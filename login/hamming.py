import nltk
import string
from nltk.tokenize import word_tokenize
from scipy.spatial.distance import hamming
from Levenshtein import distance
from nltk.corpus import stopwords
import math
