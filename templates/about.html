{% extends 'base_layout.html' %} {% block content %}
<!-- <p
  class="display-2 text-primary"
  style="border-bottom: 1px solid rgb(205, 231, 241)"
>
  About Us
</p> -->
<p class="h1 text-center text-primary">Student Grading Using Text Similarity</p>
<p class="text-center fs-3 text-info">By 
  <ul class="list-unstyled text-center lead">
    <li>Tishme Hasan</li>
    <li>Amanta Hossain</li>
    <li>Md Abir Reza Pial</li>
    <li>Md Mahmudul Hasan</li>
    <li>Md Zishan Mahmud</li>
  </ul>
</p>
<hr/>
<p class="text-dark ">

Text similarity measurement is one of the most important issues in the current world. We are continually working to enhance our system to reduce human error while achiev- ing high accuracy, and a written answer test—a form of assessment in which no response alternatives are offered and which is designed to gauge student’s level of topic understand- ing—is being employed to achieve this goal. Manually evaluating the quality of the answers is a subjective and time-consuming operation. The purpose of this research is to create a text similarity system that will enable teachers to evaluate a script by comparing it to a sample response saved in the system to provide an automated approach of evaluating text responses based on Jaro-Winkler. The calculated results are in real time to a remote server, the results in this case must be relevant and obtained very quickly. The objective is to not only shorten the time and eliminate any risk of biasness but also explores the potential of text similarity-based grading to improve the grading process.
</p>
<p class="badge bg-primary text-wrap text-center">©Team Corpus | 2023</p>
{% endblock %}
